{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19955cc4-fde4-405c-ab6c-313e82fa8947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing index es_clients_with_duplicates\n",
      "Created index es_clients_with_duplicates with custom settings and mappings\n",
      "Data uploaded to index es_clients_with_duplicates\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from elasticsearch_dsl import Search, Q\n",
    "\n",
    "## All information is randomly generated, contains no PII whatsoever\n",
    "\n",
    "# Import CSV to df\n",
    "df_clients_with_duplicates = pd.read_csv('csv/clients_with_duplicates.csv')\n",
    "\n",
    "# Replace all NaN values with an empty string\n",
    "df_clients_with_duplicates.fillna('', inplace=True)\n",
    "\n",
    "# Reduce number of entries\n",
    "df_clients_with_duplicates = df_clients_with_duplicates.head(2000)\n",
    "\n",
    "def setup_elasticsearch_index(df, index_name):\n",
    "    # Initialize Elasticsearch client\n",
    "    es = Elasticsearch(\n",
    "        'https://elastic:9200',\n",
    "        basic_auth=('elastic', 'password'),\n",
    "        verify_certs=False,\n",
    "        ssl_show_warn=False\n",
    "    )\n",
    "    # Delete the index if it exists\n",
    "    if es.indices.exists(index=index_name):\n",
    "        es.indices.delete(index=index_name)\n",
    "        print(f\"Deleted existing index {index_name}\")\n",
    "\n",
    "    # Create the index with optimized settings for text analysis\n",
    "    settings = {\n",
    "        \"settings\": {\n",
    "            \"analysis\": {\n",
    "                \"analyzer\": {\n",
    "                    \"custom_text_analyzer\": {\n",
    "                        \"type\": \"custom\",\n",
    "                        \"tokenizer\": \"whitespace\",\n",
    "                        \"filter\": [\"lowercase\", \"asciifolding\"]\n",
    "                    }\n",
    "                },\n",
    "                \"normalizer\": {\n",
    "                    \"custom_normalizer\": {\n",
    "                        \"type\": \"custom\",\n",
    "                        \"filter\": [\"lowercase\", \"asciifolding\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"name\": {\"type\": \"text\", \"analyzer\": \"custom_text_analyzer\"},\n",
    "                \"email1\": {\"type\": \"text\", \"analyzer\": \"custom_text_analyzer\"},\n",
    "                \"email2\": {\"type\": \"text\", \"analyzer\": \"custom_text_analyzer\"},\n",
    "                \"legal\": {\"type\": \"keyword\", \"normalizer\": \"custom_normalizer\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.create(index=index_name, body=settings)\n",
    "    print(f\"Created index {index_name} with custom settings and mappings\")\n",
    "\n",
    "    # Create an iterable of actions to be executed in bulk\n",
    "    actions = [\n",
    "        {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": str(record['id']),\n",
    "            \"_source\": record,\n",
    "        }\n",
    "        for record in df.to_dict(orient='records')\n",
    "    ]\n",
    "    \n",
    "    # Perform bulk insert\n",
    "    helpers.bulk(es, actions)\n",
    "    # Refresh the index to make the changes searchable\n",
    "    es.indices.refresh(index=index_name)\n",
    "    print(f\"Data uploaded to index {index_name}\")\n",
    "\n",
    "setup_elasticsearch_index(df_clients_with_duplicates, 'es_clients_with_duplicates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b341a9-353e-4818-af86-bd0985dd9e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>email1</th>\n",
       "      <th>email2</th>\n",
       "      <th>legal</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>44779</td>\n",
       "      <td>Alma Miranda</td>\n",
       "      <td>15/6/2022</td>\n",
       "      <td>amiranda@523344123.net</td>\n",
       "      <td>amiranda@outlook.456</td>\n",
       "      <td>Y9245502</td>\n",
       "      <td>email1_amiranda@523344123.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47578</td>\n",
       "      <td>Ariel Miranda</td>\n",
       "      <td>13/6/2019</td>\n",
       "      <td>amiranda@523344123.net</td>\n",
       "      <td>amiranda@yahoo.123</td>\n",
       "      <td>Y8885086</td>\n",
       "      <td>email1_amiranda@523344123.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>46148</td>\n",
       "      <td>Evan Griffith</td>\n",
       "      <td>5/2/2023</td>\n",
       "      <td>egriffith@yahoo.123</td>\n",
       "      <td>eva_gri@523344123.net</td>\n",
       "      <td>Y9601865</td>\n",
       "      <td>email1_egriffith@yahoo.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51148</td>\n",
       "      <td>Evan Grìffith</td>\n",
       "      <td>05/02/2020</td>\n",
       "      <td>egriffith@yahoo.123</td>\n",
       "      <td>egriffith@yahoo.123</td>\n",
       "      <td>X4792429</td>\n",
       "      <td>email1_egriffith@yahoo.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>49676</td>\n",
       "      <td>Enoch Hendérson</td>\n",
       "      <td>16/03/2018</td>\n",
       "      <td>ehenderson@523344123.net</td>\n",
       "      <td></td>\n",
       "      <td>Y1923489</td>\n",
       "      <td>email1_ehenderson@523344123.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>44144</td>\n",
       "      <td>Ezra Stephens</td>\n",
       "      <td>19/2/2024</td>\n",
       "      <td>estephens@hotmail.abc</td>\n",
       "      <td>ezrastephens90@outlook.456</td>\n",
       "      <td>Z6441458</td>\n",
       "      <td>legal_Z6441458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>47502</td>\n",
       "      <td>Amari Khan</td>\n",
       "      <td>9/2/2023</td>\n",
       "      <td>akhan@yahoo.123</td>\n",
       "      <td>akhan@gmx.bbb</td>\n",
       "      <td>Z7069861</td>\n",
       "      <td>legal_Z7069861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>44041</td>\n",
       "      <td>Denisse Li</td>\n",
       "      <td>6/9/2024</td>\n",
       "      <td>dli@yahoo.123</td>\n",
       "      <td>den_li@gmail.xyz</td>\n",
       "      <td>Z7069861</td>\n",
       "      <td>legal_Z7069861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>43301</td>\n",
       "      <td>Whitley McLaughlin</td>\n",
       "      <td>28/11/2020</td>\n",
       "      <td>whitleymclaughlin54@523344123.net</td>\n",
       "      <td>whi_mcl@523344123.net</td>\n",
       "      <td>Z9120239</td>\n",
       "      <td>legal_Z9120239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>44038</td>\n",
       "      <td>Case Rogers</td>\n",
       "      <td>19/6/2022</td>\n",
       "      <td>caserogers84@gmail.xyz</td>\n",
       "      <td>caserogers83@gmx.bbb</td>\n",
       "      <td>Z9120239</td>\n",
       "      <td>legal_Z9120239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                name        date                             email1  \\\n",
       "82   44779        Alma Miranda   15/6/2022             amiranda@523344123.net   \n",
       "9    47578       Ariel Miranda   13/6/2019             amiranda@523344123.net   \n",
       "73   46148       Evan Griffith    5/2/2023                egriffith@yahoo.123   \n",
       "10   51148       Evan Grìffith  05/02/2020                egriffith@yahoo.123   \n",
       "128  49676     Enoch Hendérson  16/03/2018           ehenderson@523344123.net   \n",
       "..     ...                 ...         ...                                ...   \n",
       "125  44144       Ezra Stephens   19/2/2024              estephens@hotmail.abc   \n",
       "92   47502          Amari Khan    9/2/2023                    akhan@yahoo.123   \n",
       "55   44041          Denisse Li    6/9/2024                      dli@yahoo.123   \n",
       "163  43301  Whitley McLaughlin  28/11/2020  whitleymclaughlin54@523344123.net   \n",
       "136  44038         Case Rogers   19/6/2022             caserogers84@gmail.xyz   \n",
       "\n",
       "                         email2     legal                         group_id  \n",
       "82         amiranda@outlook.456  Y9245502    email1_amiranda@523344123.net  \n",
       "9            amiranda@yahoo.123  Y8885086    email1_amiranda@523344123.net  \n",
       "73        eva_gri@523344123.net  Y9601865       email1_egriffith@yahoo.123  \n",
       "10          egriffith@yahoo.123  X4792429       email1_egriffith@yahoo.123  \n",
       "128                              Y1923489  email1_ehenderson@523344123.net  \n",
       "..                          ...       ...                              ...  \n",
       "125  ezrastephens90@outlook.456  Z6441458                   legal_Z6441458  \n",
       "92                akhan@gmx.bbb  Z7069861                   legal_Z7069861  \n",
       "55             den_li@gmail.xyz  Z7069861                   legal_Z7069861  \n",
       "163       whi_mcl@523344123.net  Z9120239                   legal_Z9120239  \n",
       "136        caserogers83@gmx.bbb  Z9120239                   legal_Z9120239  \n",
       "\n",
       "[174 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a cross-comparison among all documents in the index for any given field\n",
    "def find_potential_duplicates(index_name):\n",
    "    es = Elasticsearch(\n",
    "        'https://elastic:9200',\n",
    "        basic_auth=('elastic', 'password'),\n",
    "        verify_certs=False,\n",
    "        ssl_show_warn=False\n",
    "    )\n",
    "    \n",
    "    # Fetch all documents to use each as a basis for comparison\n",
    "    search = Search(using=es, index=index_name).source(['name', 'legal', 'email1', 'email2', 'id', 'date'])\n",
    "    all_docs = [doc.to_dict() for doc in search.scan()]\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    # Define the fields to be searched for duplicates and the type of search\n",
    "    fields_to_search = {\n",
    "        'name': 'fuzzy',\n",
    "        'email1': 'exact',\n",
    "        'email2': 'exact',\n",
    "        'legal': 'exact'\n",
    "    }\n",
    "\n",
    "    # Check each document against all others for each field\n",
    "    for doc in all_docs:\n",
    "        for field, match_type in fields_to_search.items():\n",
    "            if match_type == 'fuzzy':\n",
    "                query = Q('fuzzy', **{field: {'value': doc[field], 'fuzziness': 'AUTO'}})\n",
    "            else:  # Exact match for emails\n",
    "                query = Q('match', **{field: doc[field]})\n",
    "\n",
    "            search_results = Search(using=es, index=index_name).query(query).exclude('ids', values=[doc['id']])\n",
    "            duplicates = search_results.execute()\n",
    "\n",
    "            # Create a dataframe from hits and concatenate it with the results DataFrame\n",
    "            hits_df = pd.DataFrame([hit.to_dict() for hit in duplicates])\n",
    "            if not hits_df.empty:\n",
    "                # Add a grouping identifier\n",
    "                hits_df['group_id'] = f\"{field}_{doc[field]}\"\n",
    "                results_df = pd.concat([results_df, hits_df]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Sort by group_id to cluster related entries together\n",
    "    if not results_df.empty:\n",
    "        results_df = results_df.sort_values(by='group_id')\n",
    "        return results_df\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty dataframe if no duplicates found\n",
    "\n",
    "duplicate_results = find_potential_duplicates('es_clients_with_duplicates')\n",
    "duplicate_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
