{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97b27b60-9444-4362-8e68-ec281a8d6cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique transaction id</th>\n",
       "      <th>date</th>\n",
       "      <th>transaction type</th>\n",
       "      <th>sender</th>\n",
       "      <th>description</th>\n",
       "      <th>amount</th>\n",
       "      <th>bank search terms</th>\n",
       "      <th>matched client id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000</td>\n",
       "      <td>24/11/22</td>\n",
       "      <td>direct debit received</td>\n",
       "      <td>Acme Inc.</td>\n",
       "      <td>Lwilkerson</td>\n",
       "      <td>701.16</td>\n",
       "      <td>Acme Inc. Lwilkerson</td>\n",
       "      <td>33153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000001</td>\n",
       "      <td>27/02/22</td>\n",
       "      <td>rejected direct debit</td>\n",
       "      <td>Witch Foods</td>\n",
       "      <td>Globex Corporation</td>\n",
       "      <td>-223.16</td>\n",
       "      <td>Witch Foods Globex Corporation</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000002</td>\n",
       "      <td>13/01/22</td>\n",
       "      <td>direct debit received</td>\n",
       "      <td>Acme Inc.</td>\n",
       "      <td>Gaven Ariana 4 8</td>\n",
       "      <td>386.13</td>\n",
       "      <td>Acme Inc. Gaven Ariana 4 8</td>\n",
       "      <td>33139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000003</td>\n",
       "      <td>21/05/22</td>\n",
       "      <td>transfer received</td>\n",
       "      <td>Globex Corporation</td>\n",
       "      <td>Jessie and Raymond</td>\n",
       "      <td>732.43</td>\n",
       "      <td>Globex Corporation Jessie and Raymond</td>\n",
       "      <td>33126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000004</td>\n",
       "      <td>06/05/22</td>\n",
       "      <td>Bank fee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-272.75</td>\n",
       "      <td></td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000005</td>\n",
       "      <td>25/04/22</td>\n",
       "      <td>direct debit received</td>\n",
       "      <td>Acme Inc.</td>\n",
       "      <td>Bob</td>\n",
       "      <td>581.58</td>\n",
       "      <td>Acme Inc. Bob</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000006</td>\n",
       "      <td>13/03/22</td>\n",
       "      <td>transfer received</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33129</td>\n",
       "      <td>856.76</td>\n",
       "      <td>33129</td>\n",
       "      <td>33129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10000007</td>\n",
       "      <td>22/02/22</td>\n",
       "      <td>Expense payment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-434.58</td>\n",
       "      <td></td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000008</td>\n",
       "      <td>13/12/22</td>\n",
       "      <td>Bank fee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-196.26</td>\n",
       "      <td></td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000009</td>\n",
       "      <td>07/10/22</td>\n",
       "      <td>transfer received</td>\n",
       "      <td>Initech</td>\n",
       "      <td>Savanna Lugo</td>\n",
       "      <td>376.48</td>\n",
       "      <td>Initech Savanna Lugo</td>\n",
       "      <td>33116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique transaction id      date       transaction type              sender  \\\n",
       "0               10000000  24/11/22  direct debit received           Acme Inc.   \n",
       "1               10000001  27/02/22  rejected direct debit         Witch Foods   \n",
       "2               10000002  13/01/22  direct debit received           Acme Inc.   \n",
       "3               10000003  21/05/22      transfer received  Globex Corporation   \n",
       "4               10000004  06/05/22               Bank fee                 NaN   \n",
       "5               10000005  25/04/22  direct debit received           Acme Inc.   \n",
       "6               10000006  13/03/22      transfer received                 NaN   \n",
       "7               10000007  22/02/22        Expense payment                 NaN   \n",
       "8               10000008  13/12/22               Bank fee                 NaN   \n",
       "9               10000009  07/10/22      transfer received             Initech   \n",
       "\n",
       "          description  amount                      bank search terms  \\\n",
       "0          Lwilkerson  701.16                   Acme Inc. Lwilkerson   \n",
       "1  Globex Corporation -223.16         Witch Foods Globex Corporation   \n",
       "2    Gaven Ariana 4 8  386.13             Acme Inc. Gaven Ariana 4 8   \n",
       "3  Jessie and Raymond  732.43  Globex Corporation Jessie and Raymond   \n",
       "4                 NaN -272.75                                          \n",
       "5                 Bob  581.58                          Acme Inc. Bob   \n",
       "6               33129  856.76                                  33129   \n",
       "7                 NaN -434.58                                          \n",
       "8                 NaN -196.26                                          \n",
       "9        Savanna Lugo  376.48                   Initech Savanna Lugo   \n",
       "\n",
       "   matched client id  \n",
       "0              33153  \n",
       "1               <NA>  \n",
       "2              33139  \n",
       "3              33126  \n",
       "4               <NA>  \n",
       "5               <NA>  \n",
       "6              33129  \n",
       "7               <NA>  \n",
       "8               <NA>  \n",
       "9              33116  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from elasticsearch_dsl import Search, Q\n",
    "import pandas as pd\n",
    "\n",
    "## Final result example. Relevant data gets prepared, uploaded to elasticsearch, and matched against bank transactions\n",
    "\n",
    "# Load the dataframes\n",
    "df_bank = pd.read_csv('csv/01-bank.csv')\n",
    "df_client = pd.read_csv('csv/02-client.csv')\n",
    "df_student = pd.read_csv('csv/03-student.csv')\n",
    "\n",
    "# Merge the clients and students dataframes\n",
    "df_client_combined = pd.merge(df_client, df_student, left_on='client id', right_on='associated client id')\n",
    "\n",
    "# Pivot the data to put all student info in the same row as clients\n",
    "df_client_combined = df_client_combined.pivot_table(\n",
    "    index=['client id', 'name', 'last name', 'email1', 'email2', 'handle', 'account number'],\n",
    "    columns=df_client_combined.groupby(\"client id\").cumcount() + 1,\n",
    "    values=['student name', 'student last name', 'grade'],\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Flatten the previous pivot table\n",
    "df_client_combined.columns = df_client_combined.columns.to_series().apply(\n",
    "    lambda x: ' '.join(str(y) for y in x if y).strip()\n",
    ")\n",
    "\n",
    "# Prepare the bank search terms (search the sender and description values of the transactions)\n",
    "df_bank['bank search terms'] = df_bank['sender'].fillna('') + ' ' + df_bank['description'].fillna('')\n",
    "\n",
    "# Function to upload the combined client data to elasticsearch (make the data searchable)\n",
    "def upload_data_to_elasticsearch():\n",
    "    index_name = \"es_client_combined\"\n",
    "\n",
    "    # Setup Elasticsearch connection\n",
    "    es = Elasticsearch(\n",
    "        'https://elastic:9200',\n",
    "        basic_auth=('elastic', 'password'),\n",
    "        verify_certs=False,\n",
    "        ssl_show_warn=False\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Check if index exists, delete if it does\n",
    "        if es.indices.exists(index=index_name):\n",
    "            es.indices.delete(index=index_name)\n",
    "        \n",
    "        # Create a new index\n",
    "        es.indices.create(index=index_name)\n",
    "\n",
    "        # Prepare and upload data to elasticsearch\n",
    "        actions = [\n",
    "            {\n",
    "                \"_index\": index_name,\n",
    "                \"_id\": str(record['client id']),\n",
    "                \"_source\": record,\n",
    "            }\n",
    "            for record in df_client_combined.to_dict(orient='records')\n",
    "        ]\n",
    "        # Perform the bulk upload\n",
    "        helpers.bulk(es, actions)\n",
    "\n",
    "        # Refresh the index to make the changes searchable\n",
    "        es.indices.refresh(index=index_name)\n",
    "    \n",
    "    except Exception as e:\n",
    "        pass  # Handle exceptions as needed\n",
    "\n",
    "# Upload the combined client data to elasticsearch\n",
    "upload_data_to_elasticsearch()\n",
    "\n",
    "def get_highest_relevance_clientid(dataframe, index_name, min_score_difference=1.0):\n",
    "    # Establish the connection to elasticsearch\n",
    "    es = Elasticsearch(\n",
    "        'https://elastic:9200',\n",
    "        basic_auth=('elastic', 'password'),\n",
    "        verify_certs=False,\n",
    "        ssl_show_warn=False\n",
    "    )\n",
    "\n",
    "    # Get the highest relevance client id for bank search terms\n",
    "    def get_clientid(text):\n",
    "        # Clean up the search terms\n",
    "        text = text.strip()\n",
    "\n",
    "        # Skip empty search terms\n",
    "        if not text:\n",
    "            return None\n",
    "\n",
    "        # Create a multi_match query # Pending. Boost last name/client id importance, ignore single letter words (false positives)\n",
    "        query = Q('multi_match', query=text, fields=['*'], type='best_fields', minimum_should_match=1)\n",
    "        \n",
    "        # Execute the search\n",
    "        s = Search(using=es, index=index_name).query(query).extra(size=2)\n",
    "        response = s.execute()\n",
    "\n",
    "        ## This is the part that needs to be tweaked/adjusted for edge cases, along with with boosting field importance \n",
    "        # Handle ambiguity if there are multiple hits\n",
    "        if len(response.hits) > 0:\n",
    "            # If there's only one hit, or the score difference between the top two hits is above the threshold\n",
    "            if len(response.hits) == 1 or response.hits[0].meta.score - response.hits[1].meta.score >= min_score_difference:\n",
    "                return response.hits[0].meta.id\n",
    "        # Return None if the top hits are ambiguous or there are no hits\n",
    "        return None\n",
    "\n",
    "    # Search each row in the df_bank \"bank search terms\" and store the results in a new column \"matched client id\"\n",
    "    dataframe['matched client id'] = dataframe['bank search terms'].apply(get_clientid).astype('Int64')\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "# Perform the client id matching on the bank dataframe\n",
    "df_bank_matched = get_highest_relevance_clientid(df_bank, 'es_client_combined')\n",
    "\n",
    "# Display the updated dataframe with matched client id\n",
    "df_bank_matched"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
